<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Random Thoughts on Deep Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Random Thoughts on Deep Learning">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Random Thoughts on Deep Learning">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Random Thoughts on Deep Learning">
<meta name="twitter:description">
  
    <link rel="alternate" href="/atom.xml" title="Random Thoughts on Deep Learning" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Random Thoughts on Deep Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Transfer-Learning-Tips" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/02/Transfer-Learning-Tips/" class="article-date">
  <time datetime="2016-10-02T14:34:52.000Z" itemprop="datePublished">2016-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/02/Transfer-Learning-Tips/">Transfer_Learning_Tips</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I came across a post which describes the common principles to follow when apply transfer learning or fine-tuning schemes to the CNN. </p>
<p>You can find the original post here.</p>
<p><a href="http://blog.revolutionanalytics.com/2016/08/deep-learning-part-2.html" target="_blank" rel="external">http://blog.revolutionanalytics.com/2016/08/deep-learning-part-2.html</a></p>
<p>In this post, I quoted some of his statements here. </p>
<h2 id="Transfer-Learning-and-Fine-tuning-DCNNs"><a href="#Transfer-Learning-and-Fine-tuning-DCNNs" class="headerlink" title="Transfer Learning and Fine-tuning DCNNs"></a>Transfer Learning and Fine-tuning DCNNs</h2><p>In practice, we don?t usually train an entire DCNN from scratch with random initialization. This is because it is relatively rare to have a dataset of sufficient size that is required for the depth of network required. Instead, it is common to pre-train a DCNN on a very large dataset and then use the trained DCNN weights either as an initialization or a fixed feature extractor for the task of interest.</p>
<p>Fine-Tuning: Transfer learning strategies depend on various factors, but the two most important ones are the size of the new dataset, and its similarity to the original dataset. Keeping in mind that DCNN features are more generic in early layers and more dataset-specific in later layers, there are four major scenarios:</p>
<p>New dataset is smaller in size and similar in content compared to original dataset: If the data is small, it is not a good idea to fine-tune the DCNN due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the DCNN to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN-features.</p>
<p>New dataset is relatively large in size and similar in content compared to the original dataset: Since we have more data, we can have more confidence that we would not over fit if we were to try to fine-tune through the full network.</p>
<p>New dataset is smaller in size but very different in content compared to the original dataset: Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier from the top of the network, which contains more dataset-specific features. Instead, it might work better to train a classifier from activations somewhere earlier in the network.</p>
<p>New dataset is relatively large in size and very different in content compared to the original dataset: Since the dataset is very large, we may expect that we can afford to train a DCNN from scratch. However, in practice it is very often still beneficial to initialize with weights from a pre-trained model. In this case, we would have enough data and confidence to fine-tune through the entire network.<br>Fine-tuning DCNNs: For this DR prediction problem, we fall under scenario iv. We fine-tune the weights of the pre-trained DCNN by continuing the backpropagation. It is possible to fine-tune all the layers of the DCNN, or it?s possible to keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. This is motivated by the observation that the earlier features of a DCNN contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks, but later layers of the DCNN becomes progressively more specific to the details of the classes contained in the DR dataset.</p>
<p>Transfer learning constraints: As we use a pre-trained network, we are slightly constrained in terms of the model architecture. For example, we can?t arbitrarily take out convolutional layers from the pre-trained network. However, due to parameter sharing, we can easily run a pre-trained network on images of different spatial size. This is clearly evident in the case of Convolutional and Pool layers because their forward function is independent of the input volume spatial size. In case of Fully Connected (FC) layers, this still holds true because FC layers can be converted to a Convolutional Layer.</p>
<p>Learning rates: We use a smaller learning rate for DCNN weights that are being fine-tuned under the assumption that the pre-trained DCNN weights are relatively good. We don?t wish to distort them too quickly or too much, so we keep both our learning rate and learning rate decay really small.</p>
<p>Data Augmentation: One of the drawbacks of non-regularized neural networks is that they are extremely flexible: they learn both features and noise equally well, increasing the potential for overfitting. In our model, we apply L2 regularization to avoid overfitting. But even after that, we observed a large gap in model performance on the training and validation DR images, indicating that the fine tuning process is overfitting to the training set. To combat this overfitting, we leverage data augmentation for the DR image dataset.</p>
<p>There are many ways to do data augmentation, such as the popular horizontally flipping, random crops and color jittering. As the color information in these images is very important, we only rotate the images at different angles ? at 0, 90, 180, and 270 degrees.</p>
<h2 id="Other-References"><a href="#Other-References" class="headerlink" title="Other References"></a>Other References</h2><p>Andrej Karpathy@cs231n also has an intuitive explanation on how we should employ transfer learning in practice. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/02/Transfer-Learning-Tips/" data-id="citsql0az0002fps68toqiqm1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Deep-Learning-Resources" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/02/Deep-Learning-Resources/" class="article-date">
  <time datetime="2016-10-02T07:18:27.000Z" itemprop="datePublished">2016-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/02/Deep-Learning-Resources/">Deep_Learning_Resources</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I have collected a bunch of resources that might be helpful to study the field of deep learning. </p>
<h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><p>CS231n: Convolutional Neural Networks for Visual Recognition, taught by Andrej Karpathy etc.<br><a href="http://cs231n.stanford.edu" target="_blank" rel="external">http://cs231n.stanford.edu</a></p>
<p>Machine Learning: 2014-2015, taught by Nando de Freitas<br><a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" target="_blank" rel="external">https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/</a></p>
<h2 id="Lectures"><a href="#Lectures" class="headerlink" title="Lectures"></a>Lectures</h2><p>Bay Area Deep Learning School, 2016<br><a href="https://www.youtube.com/watch?v=eyovmAtoUx0" target="_blank" rel="external">https://www.youtube.com/watch?v=eyovmAtoUx0</a></p>
<p>Deep Learning Summer School, Montreal 2016<br><a href="http://videolectures.net/deeplearning2016_montreal/" target="_blank" rel="external">http://videolectures.net/deeplearning2016_montreal/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/02/Deep-Learning-Resources/" data-id="citsql0b60005fps6it00dwlg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Bay-Area-DeepLearning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/02/Bay-Area-DeepLearning/" class="article-date">
  <time datetime="2016-10-02T03:44:01.000Z" itemprop="datePublished">2016-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/02/Bay-Area-DeepLearning/">Bay_Area_DeepLearning</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I have spent the weekend to watch the video lectures given on Bay Area Deep Learning School and here are some thoughts that found to be particularly interesting, as illustrated below. </p>
<p><img src="img/20161002/dl_practice.png" alt="Deep Learning in Practice"></p>
<p><img src="img/20161002/dl_career.png" alt="Deep Learning Career Path"></p>
<p>Here is the address to watch the video.</p>
<p><a href="https://www.youtube.com/watch?v=eyovmAtoUx0" target="_blank" rel="external">https://www.youtube.com/watch?v=eyovmAtoUx0</a></p>
<p>There is also a very nice article which summarizes the notes made by Andrew Ng.</p>
<p><a href="https://kevinzakka.github.io/2016/09/26/applying-deep-learning/" target="_blank" rel="external">https://kevinzakka.github.io/2016/09/26/applying-deep-learning/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/02/Bay-Area-DeepLearning/" data-id="citsql0b30004fps6c16d8o58" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-300w" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/08/16/300w/" class="article-date">
  <time datetime="2016-08-16T08:26:16.000Z" itemprop="datePublished">2016-08-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/16/300w/">300w</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I have trained a 68 point landmark detector with CNN. The input dimension is 40*40 and the enclosing bounding box is generated by the min and max of the landmarks. The network structure still follows the VanillaCNN structure. </p>
<p>Some landmark detection results are shown as below.</p>
<div id="image-table"><br>    <table><br>        <tr><br>            <td style="padding:5px"><br>                <img src="img/20160816/out_0/image_0001.png" height="200" width="250"><br>              </td><br>            <td style="padding:5px"><br>                <img src="img/20160816/out_0/image_0002.png" height="200" width="250"><br>             </td><br>            <td style="padding:5px"><br>                <img src="img/20160816/out_0/image_0008.png" height="200" width="250"><br>             </td><br>             <td style="padding:5px"><br>                <img src="img/20160816/out_0/image_0022.png" height="200" width="250"><br>             </td><br>        </tr><br>    </table><br></div>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/08/16/300w/" data-id="citsql0as0000fps6p4lkp4nj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Multitask-CNN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/19/Multitask-CNN/" class="article-date">
  <time datetime="2016-07-19T15:08:37.000Z" itemprop="datePublished">2016-07-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/19/Multitask-CNN/">Multitask_CNN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Face landmark detection can be combined with other tasks, such as gender classification, pose estimation and so on. This is usually referred as multi-task CNN learning in this context. It is not very difficult to adapt a single-task CNN to a multi-task CNN. We only need to modify the prototxt file and properly define the input and ouput data structures. Here I given an example of multi-task CNN based on VanillaCNN structure.</p>
<p>The network structure is given as follows:</p>
<p><img src="img/20160719/vanilla_multitask.png" alt="VanillaCNN_Multitask"></p>
<p>The dataset is provided as follows:</p>
<p><a href="http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html</a></p>
<p>A recent work, namely “HyperFace”, also provides very detailed analysis on how we can perform multi-task learning with CNN. The presented ideas are very straightforward and can be easily implemented, at least for the multi-task CNN part or the individual parts. </p>
<p><a href="http://arxiv.org/abs/1603.01249" target="_blank" rel="external">http://arxiv.org/abs/1603.01249</a></p>
<p>You can see the HyperFace network structure here. I have briefly copied the figure from the paper. </p>
<p><img src="img/20160719/hyperface.png" alt="HyperFace"></p>
<p>Besides, you can also check the multitask network structure. </p>
<p><img src="img/20160719/multitask_face.png" alt="HyperFace"></p>
<p>As mentioned in the paper, the networks are modified from the Region-based CNN, which is derived from AlexNet. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/19/Multitask-CNN/" data-id="citsql0b20003fps63jjed6g8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-vanillacnn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/28/vanillacnn/" class="article-date">
  <time datetime="2016-06-28T13:40:03.000Z" itemprop="datePublished">2016-06-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/28/vanillacnn/">vanillacnn</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Face alignment can be solved by applying a very straightforward CNN approach. That means we can “tweak” traditional CNN used by image classification to do regression task for face alignment. </p>
<p>Yue Wu<em>, Tal Hassner</em>, KangGeon Kim, Gerard Medioni and Prem Natarajan, Facial Landmark Detection with Tweaked Convolutional Neural Networks, arXiv preprint arXiv:1511.04031, 21 Mar 2016</p>
<p><a href="http://www.openu.ac.il/home/hassner/projects/tcnn_landmarks/" target="_blank" rel="external">http://www.openu.ac.il/home/hassner/projects/tcnn_landmarks/</a></p>
<p>ishay2b@github.com has implementation for this paper, basically the VanillaCNN part.<br><a href="https://github.com/ishay2b/VanillaCNN" target="_blank" rel="external">https://github.com/ishay2b/VanillaCNN</a></p>
<p>I have retrained the model with the MTFL dataset (10,000) images with five landmarks annotated. The test is AFLW dataset with 2995 images (~3000). You can access the MTFL dataset from the following link:<br><a href="http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html</a></p>
<p>It is noted that the same training dataset has been used in cascaded CNN work.<br><a href="http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm</a></p>
<p>So please do not confuse with the naming conventions used in the package. </p>
<p>The first step is to retrain the model by using the provided package. The default set of parameters is used. </p>
<h2 id="Experimental-Result"><a href="#Experimental-Result" class="headerlink" title="Experimental Result"></a>Experimental Result</h2><h3 id="Results-on-AFLW-and-AFW-datasets-by-VanillaCNN"><a href="#Results-on-AFLW-and-AFW-datasets-by-VanillaCNN" class="headerlink" title="Results on AFLW and AFW datasets by VanillaCNN"></a>Results on AFLW and AFW datasets by VanillaCNN</h3><p>Test Error AFLW: 8.545266 mean error, 2535 items, 606 failures  0.239053 precent<br>Test Error AFW:  7.905281 mean error, 141 items, 25 failures  0.177305 precent</p>
<h3 id="Results-on-AFLW-and-AFW-datasets-by-ECCV-14-paper"><a href="#Results-on-AFLW-and-AFW-datasets-by-ECCV-14-paper" class="headerlink" title="Results on AFLW  and AFW datasets by ECCV 14 paper"></a>Results on AFLW  and AFW datasets by ECCV 14 paper</h3><p>Test Error AFLW: 8.545266 mean error, 8.0<br>Test Error AFW: 8.545266 mean error, 8.2</p>
<h2 id="Visualization-the-Network"><a href="#Visualization-the-Network" class="headerlink" title="Visualization the Network"></a>Visualization the Network</h2><p>I have plotted the CNN network used in this experiment.</p>
<p><img src="img/VanillaCNN.png" alt="Vanilla CNN Network"></p>
<h2 id="Face-Alignment-Results-on-LFPW-dataset"><a href="#Face-Alignment-Results-on-LFPW-dataset" class="headerlink" title="Face Alignment Results on LFPW dataset"></a>Face Alignment Results on LFPW dataset</h2><div id="image-table"><br>    <table><br>        <tr><br>            <td style="padding:5px"><br>                <img src="img/VanillaCNN_detection/0132-image31201.jpg" height="200" width="250"><br>              </td><br>            <td style="padding:5px"><br>                <img src="img/VanillaCNN_detection/0177-image71131.jpg" height="200" width="250"><br>             </td><br>            <td style="padding:5px"><br>                <img src="img/VanillaCNN_detection/0223-image08358.jpg" height="200" width="250"><br>             </td><br>                        <td style="padding:5px"><br>                <img src="img/VanillaCNN_detection/0275-image17840.jpg" height="200" width="250"><br>             </td><br>        </tr><br>    </table><br></div>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/28/vanillacnn/" data-id="citsql0ba0007fps6dqgu25kf" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CNN-for-Facial-Point-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/20/CNN-for-Facial-Point-Detection/" class="article-date">
  <time datetime="2016-06-20T15:21:36.000Z" itemprop="datePublished">2016-06-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/20/CNN-for-Facial-Point-Detection/">CNN for Facial Point Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>After Alexnet won 2012 ImageNet competition, deep learning has become one of the most promising fields in the computer vision field. Convolutional Neural Network (CNN) has attracted much attention since then. </p>
<p>Tang’s group has proposed the use of CNN in a cascade manner to train the landmark detection from coarse to fine. </p>
<p>Reference: Y. Sun, X. Wang, and X. Tang. Deep Convolutional Network Cascade for Facial Point Detection. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013. </p>
<p>Here is an implementation for the above proposed method, thanks to luoyetx@github.com.</p>
<p><a href="https://github.com/luoyetx/deep-landmark" target="_blank" rel="external">https://github.com/luoyetx/deep-landmark</a></p>
<p>I have retrained the code with just one level, i.e., full face region with five landmarks. The results seem to be pretty good.</p>
<p>I have used the provided dataset from the website to train the CNN at level 1, which contains 5,590 LFW images and 7,876 other images. </p>
<h2 id="Experimental-Result"><a href="#Experimental-Result" class="headerlink" title="Experimental Result"></a>Experimental Result</h2><h3 id="Results-on-7-876-images"><a href="#Results-on-7-876-images" class="headerlink" title="Results on 7,876 images"></a>Results on 7,876 images</h3><p>Test Number: 3466<br>Time Consume: 69.566 s<br>FPS: 49.823<br>LEVEL - 1<br>Mean Error:<br>    Left Eye       = 0.022343<br>    Right Eye      = 0.023272<br>    Nose           = 0.030272<br>    Left Mouth     = 0.028617<br>    Right Mouth    = 0.028821<br>Failure:<br>    Left Eye       = 0.059146<br>    Right Eye      = 0.063474<br>    Nose           = 0.140219<br>    Left Mouth     = 0.111079<br>    Right Mouth    = 0.118003</p>
<h2 id="Visualization-the-Network"><a href="#Visualization-the-Network" class="headerlink" title="Visualization the Network"></a>Visualization the Network</h2><p>I have plotted the CNN network used in this experiment.</p>
<p><img src="img/cascade_cnn.jpg" alt="CNN network"></p>
<h2 id="Face-Alignment-Results-on-LFPW-dataset"><a href="#Face-Alignment-Results-on-LFPW-dataset" class="headerlink" title="Face Alignment Results on LFPW dataset"></a>Face Alignment Results on LFPW dataset</h2><div id="image-table"><br>    <table><br>        <tr><br>            <td style="padding:5px"><br>                <img src="img/20160220/log/156.jpg" alt="Demo Result 1" height="200" width="250"><br>              </td><br>            <td style="padding:5px"><br>                <img src="img/20160220/log/159.jpg" alt="Demo Result 2" height="200" width="250"><br>             </td><br>        </tr><br>    </table><br></div>

<p>However, by using Level 1 is not sufficient in this case.  We still need to add more levels to train the CNN. Level 1 just provides a coarse estimation of landmark here.</p>
<div id="image-table"><br>    <table><br>        <tr><br>            <td style="padding:5px"><br>                <img src="img/20160220/log/163.jpg" alt="Demo Result 3" height="200" width="250"><br>              </td><br>            <td style="padding:5px"><br>                <img src="img/20160220/log/167.jpg" alt="Demo Result 4" height="200" width="250"><br>             </td><br>        </tr><br>    </table><br></div>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/20/CNN-for-Facial-Point-Detection/" data-id="citsql0ax0001fps6nakk7jic" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/17/hello-world/" class="article-date">
  <time datetime="2016-06-17T14:26:44.000Z" itemprop="datePublished">2016-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/17/hello-world/">Caffe Visualization</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>The visualization of deep learning network is very helpful to understand the global structure of how the network is evolved. Fortunately, caffe has already provided such a tool to visualize the network, namely via plotting the nets defined in prototxt file. </p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Install-the-graphviz"><a href="#Install-the-graphviz" class="headerlink" title="Install the graphviz"></a>Install the graphviz</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pip install pydot</span><br><span class="line">$ sudo apt-get instll graphviz</span><br></pre></td></tr></table></figure>
<h3 id="Execute-the-commands"><a href="#Execute-the-commands" class="headerlink" title="Execute the commands"></a>Execute the commands</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> caffe/examples</span><br><span class="line">$ python python/draw_net.py  yourPath.prototxt yourNetwork.name</span><br></pre></td></tr></table></figure>
<h2 id="Visualization-Results"><a href="#Visualization-Results" class="headerlink" title="Visualization Results"></a>Visualization Results</h2><p>I have plotted two CNN networks which have been used to perform face landmark detection. The task of face landmark detection uses HDF5 format to store the input and switch the last layer of classifier to regression. </p>
<p><img src="img/cascade_cnn.jpg" alt="CNN network used in luoyetx@github.com"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/17/hello-world/" data-id="citsql0b90006fps6fgd07vnu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/10/02/Transfer-Learning-Tips/">Transfer_Learning_Tips</a>
          </li>
        
          <li>
            <a href="/2016/10/02/Deep-Learning-Resources/">Deep_Learning_Resources</a>
          </li>
        
          <li>
            <a href="/2016/10/02/Bay-Area-DeepLearning/">Bay_Area_DeepLearning</a>
          </li>
        
          <li>
            <a href="/2016/08/16/300w/">300w</a>
          </li>
        
          <li>
            <a href="/2016/07/19/Multitask-CNN/">Multitask_CNN</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Cunjian Chen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>